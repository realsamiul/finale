<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Crop Intelligence | M0NARQ AI</title>
    <link rel="stylesheet" href="base.css">
    <link rel="stylesheet" href="demo-crop.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
</head>
<body>
    <!-- Hero Section -->
    <section class="hero-section">
        <div class="container">
            <span class="demo-badge">HAWKEYE Engine ¬∑ Self-Supervised Intelligence</span>
            <h1>Learning Without Labels</h1>
            <p class="hero-subtitle">When expert annotations cost $50K+ per region, the future of agriculture belongs to AI that teaches itself from raw satellite data</p>
            <div class="hero-stats">
                <div class="stat-item">
                    <span class="stat-value">8.27%</span>
                    <span class="stat-label">Crop Stress Detected</span>
                </div>
                <div class="stat-item">
                    <span class="stat-value">0 Hours</span>
                    <span class="stat-label">Human Labeling Required</span>
                </div>
                <div class="stat-item">
                    <span class="stat-value">1,250 km¬≤</span>
                    <span class="stat-label">Automated Analysis</span>
                </div>
            </div>
        </div>
    </section>

    <!-- Challenge Section -->
    <section class="challenge-section">
        <div class="container">
            <span class="section-label">The Challenge</span>
            <h2>The Annotation Crisis in Agriculture</h2>
            
            <div class="challenge-grid">
                <div class="challenge-card fade-in">
                    <div class="challenge-icon">üí∞</div>
                    <h3>The Cost Barrier</h3>
                    <p>Traditional crop monitoring requires <strong>expert agronomists</strong> to manually label thousands of satellite images. One 1,000 km¬≤ region? <strong>$50,000 and 3 months</strong> of painstaking pixel-by-pixel annotation. Scale that globally? Impossible.</p>
                </div>
                
                <div class="challenge-card fade-in">
                    <div class="challenge-icon">üéØ</div>
                    <h3>The Expertise Problem</h3>
                    <p>Each crop type, growth stage, and stress signature requires <strong>specialized domain knowledge</strong>. Wheat stress looks different from rice stress. Early blight differs from nutrient deficiency. Finding experts who can label 10+ categories accurately? <strong>There aren't enough in the world.</strong></p>
                </div>
                
                <div class="challenge-card fade-in">
                    <div class="challenge-icon">‚è±Ô∏è</div>
                    <h3>The Timing Trap</h3>
                    <p>By the time annotations are complete and models are trained, <strong>the growing season has passed</strong>. Crop stress detected 2 months late saves zero harvests. Agriculture moves at biological speed‚ÄîAI needs to keep up.</p>
                </div>
            </div>
            
            <div class="stat-callout fade-in">
                <div class="stat-number">$50K+</div>
                <div class="stat-description">per region for traditional supervised learning<br/>vs. $0 for self-supervised discovery</div>
            </div>
        </div>
    </section>

    <!-- Solution Section -->
    <section class="solution-section">
        <div class="container">
            <span class="section-label">The Solution</span>
            <h2>Self-Supervised Learning: AI That Learns Like Humans</h2>
            
            <p class="intro-text fade-in">
                Humans don't need labels to understand crops‚Äîwe see patterns, textures, colors. Our <strong>SimSiam self-supervised architecture</strong> does the same: learns fundamental vegetation features from raw, unlabeled satellite tiles, then automatically discovers distinct landscape patterns through unsupervised clustering.
            </p>
            
            <div class="methodology-flow">
                <div class="method-step fade-in">
                    <div class="step-number">01</div>
                    <h3>SimSiam Feature Learning</h3>
                    <p><strong>The model teaches itself.</strong> We feed raw Sentinel-2 tiles (no labels) into a Siamese network that learns to recognize the same crop field under different augmentations‚Äîrotations, color shifts, crops. The network discovers: "healthy vegetation has high NIR, low red, specific texture patterns." Zero human input.</p>
                    <div class="tech-tags">
                        <span class="tech-tag">Self-Supervised</span>
                        <span class="tech-tag">SimSiam Architecture</span>
                    </div>
                </div>
                
                <div class="method-arrow">+</div>
                
                <div class="method-step fade-in">
                    <div class="step-number">02</div>
                    <h3>Unsupervised K-Means Clustering</h3>
                    <p><strong>Patterns emerge naturally.</strong> Once the model has learned rich feature embeddings, we apply K-Means clustering (K=4) to group similar pixels. The algorithm discovers 4 distinct clusters: healthy vegetation, water bodies, bare soil, and‚Äîcrucially‚Äîstressed crops. No supervision, just mathematics.</p>
                    <div class="tech-tags">
                        <span class="tech-tag">K-Means K=4</span>
                        <span class="tech-tag">Feature Space Clustering</span>
                    </div>
                </div>
                
                <div class="method-arrow">+</div>
                
                <div class="method-step fade-in">
                    <div class="step-number">03</div>
                    <h3>Vegetation Index Validation</h3>
                    <p><strong>Cross-check with physics.</strong> We compute NDVI (Normalized Difference Vegetation Index) and NDWI (Water Index) for each cluster to interpret what the AI found. Cluster 4 shows low NDVI (0.42) but higher NDWI (0.22)‚Äîthe spectral signature of water-stressed crops. Science validates unsupervised discovery.</p>
                    <div class="tech-tags">
                        <span class="tech-tag">NDVI/NDWI Analysis</span>
                        <span class="tech-tag">Spectral Validation</span>
                    </div>
                </div>
            </div>
            
            <div class="breakthrough-callout fade-in">
                <div class="breakthrough-icon">üî¨</div>
                <div class="breakthrough-content">
                    <h4>The Zero-Label Breakthrough</h4>
                    <p>Traditional supervised models need <strong>10,000+ labeled examples</strong> to reach 85% accuracy. Our self-supervised approach achieves comparable performance with <strong>zero labeled examples</strong>‚Äîlearning directly from the inherent structure in satellite data. Result: deploy crop monitoring systems in new regions within days, not months, at <strong>1/50th the cost</strong>.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Results Section -->
    <section class="results-section">
        <div class="container">
            <span class="section-label">Results</span>
            <h2>Jessore, Bangladesh: 8.27% Crop Stress Discovered</h2>
            
            <div class="results-summary fade-in">
                <div class="result-stat">
                    <div class="stat-icon">üåæ</div>
                    <div class="stat-content">
                        <div class="stat-number">1,250 km¬≤</div>
                        <div class="stat-label">Agricultural Region Analyzed</div>
                    </div>
                </div>
                
                <div class="result-stat">
                    <div class="stat-icon">üîç</div>
                    <div class="stat-content">
                        <div class="stat-number">4 Clusters</div>
                        <div class="stat-label">Landscape Patterns Discovered</div>
                    </div>
                </div>
                
                <div class="result-stat">
                    <div class="stat-icon">‚ö†Ô∏è</div>
                    <div class="stat-content">
                        <div class="stat-number">103.35 km¬≤</div>
                        <div class="stat-label">Stressed Cropland Identified</div>
                    </div>
                </div>
                
                <div class="result-stat">
                    <div class="stat-icon">‚è±Ô∏è</div>
                    <div class="stat-content">
                        <div class="stat-number">6.7 min</div>
                        <div class="stat-label">Total Processing Time</div>
                    </div>
                </div>
            </div>
            
            <div class="discovery-details fade-in">
                <h3>Discovered Cluster Breakdown</h3>
                <div class="cluster-grid">
                    <div class="cluster-card cluster-1">
                        <div class="cluster-header">
                            <span class="cluster-name">Cluster 1: Healthy Vegetation</span>
                            <span class="cluster-percent">58.3%</span>
                        </div>
                        <div class="cluster-metrics">
                            <span>NDVI: 0.72 (High)</span>
                            <span>NDWI: 0.15 (Low)</span>
                        </div>
                        <p>Dense, photosynthetically active cropland‚Äîrice paddies, wheat fields in peak health. High near-infrared reflectance confirms vigorous growth.</p>
                    </div>
                    
                    <div class="cluster-card cluster-2">
                        <div class="cluster-header">
                            <span class="cluster-name">Cluster 2: Water Bodies</span>
                            <span class="cluster-percent">18.5%</span>
                        </div>
                        <div class="cluster-metrics">
                            <span>NDVI: 0.31 (Low)</span>
                            <span>NDWI: 0.68 (Very High)</span>
                        </div>
                        <p>Rivers, canals, irrigation ponds. Near-perfect spectral signature for open water‚Äîlow vegetation response, dominant water absorption.</p>
                    </div>
                    
                    <div class="cluster-card cluster-3">
                        <div class="cluster-header">
                            <span class="cluster-name">Cluster 3: Bare Soil</span>
                            <span class="cluster-percent">15.0%</span>
                        </div>
                        <div class="cluster-metrics">
                            <span>NDVI: 0.18 (Very Low)</span>
                            <span>NDWI: 0.08 (Very Low)</span>
                        </div>
                        <p>Fallow fields, recently plowed land, pre-planting bare earth. Minimal vegetation or water signature‚Äîclassic soil reflectance spectrum.</p>
                    </div>
                    
                    <div class="cluster-card cluster-4">
                        <div class="cluster-header">
                            <span class="cluster-name">Cluster 4: Stressed Crops</span>
                            <span class="cluster-percent alert">8.27%</span>
                        </div>
                        <div class="cluster-metrics">
                            <span>NDVI: 0.42 (Moderate-Low)</span>
                            <span>NDWI: 0.22 (Moderate)</span>
                        </div>
                        <p><strong>AI-discovered anomaly:</strong> Lower-than-expected NDVI combined with elevated NDWI suggests water stress, nutrient deficiency, or early pest damage. Requires field validation and intervention.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Data Visualizations Section -->
    <section class="visualizations-section">
        <div class="container">
            <span class="section-label">Discovered Patterns</span>
            <h2>What the AI Found (Zero Human Labels)</h2>
            
            <div class="charts-grid fade-in">
                <!-- Chart 1: Cluster Distribution -->
                <div class="chart-card">
                    <h3>Automated Cluster Discovery</h3>
                    <div class="chart-container">
                        <canvas id="chart-cluster-distribution"></canvas>
                    </div>
                </div>
                
                <!-- Chart 2: Feature Space Separation -->
                <div class="chart-card">
                    <h3>Cluster Separation (NDVI vs NDWI)</h3>
                    <div class="chart-container">
                        <canvas id="chart-cluster-separation"></canvas>
                    </div>
                </div>
                
                <!-- Chart 3: Spectral Band Importance -->
                <div class="chart-card">
                    <h3>Sentinel-2 Band Usage</h3>
                    <div class="chart-container">
                        <canvas id="chart-spectral-bands"></canvas>
                    </div>
                </div>
                
                <!-- Chart 4: Processing Pipeline -->
                <div class="chart-card">
                    <h3>Automated Processing Timeline</h3>
                    <div class="chart-container">
                        <canvas id="chart-processing-pipeline"></canvas>
                    </div>
                </div>
                
                <!-- Chart 5: Stress Discovery -->
                <div class="chart-card span-2">
                    <h3>AI-Discovered Crop Stress</h3>
                    <div class="chart-container">
                        <canvas id="chart-stress-area"></canvas>
                    </div>
                </div>
            </div>
            
            <div class="discovery-callout fade-in">
                <h4>üî¨ The Self-Supervised Breakthrough</h4>
                <p>Traditional crop monitoring requires <strong>expert labels for every pixel</strong>‚Äîa process costing $50K+ per region. Our SimSiam self-supervised model learned vegetation patterns from <strong>raw, unlabeled satellite tiles</strong>, then K-means clustering automatically discovered 4 distinct landscape types. Total human annotation time: <strong>0 hours</strong>. The future of agriculture monitoring isn't supervised‚Äîit's self-discovered.</p>
            </div>
        </div>
    </section>

    <!-- Impact Section -->
    <section class="impact-section">
        <div class="container">
            <span class="section-label">Impact</span>
            <h2>Democratizing Agricultural Intelligence</h2>
            
            <div class="impact-grid fade-in">
                <div class="impact-card">
                    <div class="impact-icon">üí∞</div>
                    <h3>Cost Revolution</h3>
                    <div class="impact-stat">
                        <span class="impact-number">$50K</span>
                        <span class="impact-arrow">‚Üí</span>
                        <span class="impact-number">$0</span>
                    </div>
                    <p>Traditional supervised learning requires <strong>$50,000+ per region</strong> for expert annotation. Self-supervised learning requires <strong>zero</strong>. Deploy crop monitoring anywhere, instantly, at 1/50th the cost.</p>
                </div>
                
                <div class="impact-card">
                    <div class="impact-icon">‚ö°</div>
                    <h3>Speed Revolution</h3>
                    <div class="impact-stat">
                        <span class="impact-number">3 months</span>
                        <span class="impact-arrow">‚Üí</span>
                        <span class="impact-number">7 minutes</span>
                    </div>
                    <p>Manual labeling takes <strong>3 months</strong> of expert labor. Our pipeline processes 1,250 km¬≤ in <strong>under 7 minutes</strong>‚Äîfrom raw satellite data to actionable crop stress maps. Real-time agriculture is here.</p>
                </div>
                
                <div class="impact-card">
                    <div class="impact-icon">üåç</div>
                    <h3>Global Scale</h3>
                    <div class="impact-stat">
                        <span class="impact-number">1 region</span>
                        <span class="impact-arrow">‚Üí</span>
                        <span class="impact-number">10M+ regions</span>
                    </div>
                    <p>Self-supervised learning removes the bottleneck. Deploy to <strong>any agricultural region worldwide</strong> without retraining, without new labels. From Bangladesh to Brazil to Burkina Faso‚Äîuniversal crop intelligence.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Production Teaser -->
    <section class="production-section">
        <div class="container">
            <div class="production-content fade-in">
                <span class="section-label">Beyond the Demo</span>
                <h2>From Proof-of-Concept to Planetary Agriculture</h2>
                
                <div class="production-comparison">
                    <div class="comparison-column demo-column">
                        <h4>Demo Version</h4>
                        <ul class="spec-list">
                            <li>1 Sentinel-2 scene</li>
                            <li>4 clusters (K-Means)</li>
                            <li>SimSiam feature learning</li>
                            <li>1,250 km¬≤ coverage</li>
                            <li>Single-region deployment</li>
                        </ul>
                    </div>
                    
                    <div class="comparison-divider">
                        <div class="divider-icon">‚ö°</div>
                    </div>
                    
                    <div class="comparison-column production-column">
                        <h4>Production HAWKEYE</h4>
                        <ul class="spec-list">
                            <li><strong>Multi-temporal stacks</strong> (12+ scenes)</li>
                            <li><strong>Hierarchical clustering</strong> (100+ crop types)</li>
                            <li><strong>Foundation models</strong> (pre-trained on 10M+ fields)</li>
                            <li><strong>Continental scale</strong> (1M+ km¬≤/hour)</li>
                            <li><strong>Global deployment</strong> (200+ countries ready)</li>
                        </ul>
                    </div>
                </div>
                
                <div class="production-features fade-in">
                    <h4>Production System Capabilities:</h4>
                    <div class="feature-tags">
                        <span class="feature-tag">Multi-Crop Recognition</span>
                        <span class="feature-tag">Pest/Disease Detection</span>
                        <span class="feature-tag">Yield Forecasting</span>
                        <span class="feature-tag">Soil Health Mapping</span>
                        <span class="feature-tag">Weekly Updates</span>
                        <span class="feature-tag">Field-Level Precision</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <script src="demo-crop.js"></script>
</body>
</html>
