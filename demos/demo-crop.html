<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Crop Intelligence | [span_86](start_span)M0NARQ AI</title>[span_86](end_span)
    <meta name="description" content="Learning Without Labels: Self-Supervised Intelligence from raw satellite data">

    <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
    <link rel="icon" type="image/png" sizes="32x32" href="../images/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../images/favicon-16x16.png">
    <link rel="apple-touch-icon" sizes="180x180" href="../images/apple-touch-icon.png">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Michroma&family=Space+Grotesk:wght@300..700&family=IBM+Plex+Mono:wght@400;600&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="demo-base-dark.css">
    <link rel="stylesheet" href="demo-crop.css">
</head>
<body class="demo-body">

    <header class="header">
        <a href="../home.html" class="logo">M0NARQ</a>
        <nav class="nav">
            [span_87](start_span)<a href="../home.html" class="nav-link">Home</a>[span_87](end_span)
            <a href="../studio.html" class="nav-link">Studio</a>
        </nav>
        <div class="nav-indicator">
            <svg viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M7.09 5.68L6.5 0L5.91 5.68L0 6.5L5.91 7.32L6.5 13L7.09 7.32L13 6.5L7.09 5.68Z" fill="currentColor"/>
            </svg>
        </div>
    </header>

    <main class="main" data-scroll-container>
        
        <section class="hero-section" data-scroll-section>
            <div class="container">
                <span class="demo-badge">HAWKEYE Engine Â· Self-Supervised Intelligence</span>
                <h1 class="hero-title">
                    <div class="hero-line-wrapper">
                        <span class="hero-title-line">Learning Without</span>
                    </div>
                    <div class="hero-line-wrapper">
                        <span class="hero-title-line">Labels</span>
                    </div>
                </h1>
                [span_88](start_span)<p class="hero-subtitle">When expert annotations cost $50K+ per region, the future of agriculture belongs to AI that teaches itself from raw satellite data</p>[span_88](end_span)
                <div class="hero-stats">
                    <div class="stat-item">
                        <span class="stat-value">8.27%</span>
                        [span_89](start_span)<span class="stat-label">Crop Stress Detected</span>[span_89](end_span)
                    </div>
                    <div class="stat-item">
                        <span class="stat-value">0 Hours</span>
                        [span_90](start_span)<span class="stat-label">Human Labeling Required</span>[span_90](end_span)
                    </div>
                    <div class="stat-item">
                        <span class="stat-value">1,250 kmÂ²</span>
                        [span_91](start_span)<span class="stat-label">Automated Analysis</span>[span_91](end_span)
                    </div>
                </div>
            </div>
        </section>

        <section class="challenge-section" data-scroll-section>
            <div class="container">
                [span_92](start_span)<span class="section-label">The Challenge</span>[span_92](end_span)
                <h2>The Annotation Crisis in Agriculture</h2>
                <div class="challenge-grid">
                    <div class="challenge-card fade-in">
                        <div class="challenge-icon">ğŸ’°</div>
                        [span_93](start_span)<h3>The Cost Barrier</h3>[span_93](end_span)
                        <p>Traditional crop monitoring requires <strong>expert agronomists</strong> to manually label thousands of satellite images. One 1,000 kmÂ² region? <strong>$50,000 and 3 months</strong> of painstaking pixel-by-pixel annotation. Scale that globally? [span_94](start_span)Impossible.</p>[span_94](end_span)
                    </div>
                    <div class="challenge-card fade-in">
                        <div class="challenge-icon">ğŸ¯</div>
                        <h3>The Expertise Problem</h3>
                        <p>Each crop type, growth stage, and stress signature requires <strong>specialized domain knowledge</strong>. Wheat stress looks different from rice stress. Early blight differs from nutrient deficiency. Finding experts who can label 10+ categories accurately? [span_95](start_span)<strong>There aren't enough in the world.</strong></p>[span_95](end_span)
                    </div>
                    <div class="challenge-card fade-in">
                        <div class="challenge-icon">â±ï¸</div>
                        [span_96](start_span)<h3>The Timing Trap</h3>[span_96](end_span)
                        <p>By the time annotations are complete and models are trained, <strong>the growing season has passed</strong>. Crop stress detected 2 months late saves zero harvests. [span_97](start_span)Agriculture moves at biological speedâ€”AI needs to keep up.</p>[span_97](end_span)
                    </div>
                </div>
                <div class="stat-callout fade-in">
                    <div class="stat-number">$50K+</div>
                    <div class="stat-description">per region for traditional supervised learning<br/>vs. [span_98](start_span)$0 for self-supervised discovery</div>[span_98](end_span)
                </div>
            </div>
        </section>

        <section class="solution-section" data-scroll-section>
            <div class="container">
                <span class="section-label">The Solution</span>
                [span_99](start_span)<h2>Self-Supervised Learning: AI That Learns Like Humans</h2>[span_99](end_span)
                <p class="intro-text fade-in">Humans don't need labels to understand cropsâ€”we see patterns, textures, colors. [span_100](start_span)Our <strong>SimSiam self-supervised architecture</strong> does the same: learns fundamental vegetation features from raw, unlabeled satellite tiles, then automatically discovers distinct landscape patterns through unsupervised clustering.</p>[span_100](end_span)
                <div class="methodology-flow">
                    <div class="method-step fade-in">
                        <div class="step-number">01</div>
                        [span_101](start_span)<h3>SimSiam Feature Learning</h3>[span_101](end_span)
                        <p><strong>The model teaches itself.</strong> We feed raw Sentinel-2 tiles (no labels) into a Siamese network that learns to recognize the same crop field under different augmentationsâ€”rotations, color shifts, crops. The network discovers: "healthy vegetation has high NIR, low red, specific texture patterns." [span_102](start_span)Zero human input.</p>[span_102](end_span)
                        <div class="tech-tags">
                            <span class="tech-tag">Self-Supervised</span>
                            [span_103](start_span)<span class="tech-tag">SimSiam Architecture</span>[span_103](end_span)
                        </div>
                    </div>
                    <div class="method-arrow">+</div>
                    <div class="method-step fade-in">
                        <div class="step-number">02</div>
                        [span_104](start_span)<h3>Unsupervised K-Means Clustering</h3>[span_104](end_span)
                        <p><strong>Patterns emerge naturally.</strong> Once the model has learned rich feature embeddings, we apply K-Means clustering (K=4) to group similar pixels. The algorithm discovers 4 distinct clusters: healthy vegetation, water bodies, bare soil, andâ€”cruciallyâ€”stressed crops. [span_105](start_span)No supervision, just mathematics.</p>[span_105](end_span)
                        <div class="tech-tags">
                            <span class="tech-tag">K-Means K=4</span>
                            [span_106](start_span)<span class="tech-tag">Feature Space Clustering</span>[span_106](end_span)
                        </div>
                    </div>
                    <div class="method-arrow">+</div>
                    <div class="method-step fade-in">
                        [span_107](start_span)<div class="step-number">03</div>[span_107](end_span)
                        <h3>Vegetation Index Validation</h3>
                        <p><strong>Cross-check with physics.</strong> We compute NDVI (Normalized Difference Vegetation Index) and NDWI (Water Index) for each cluster to interpret what the AI found. Cluster 4 shows low NDVI (0.42) but higher NDWI (0.22)â€”the spectral signature of water-stressed crops. [span_108](start_span)Science validates unsupervised discovery.</p>[span_108](end_span)
                        <div class="tech-tags">
                            <span class="tech-tag">NDVI/NDWI Analysis</span>
                            [span_109](start_span)<span class="tech-tag">Spectral Validation</span>[span_109](end_span)
                        </div>
                    </div>
                </div>
                <div class="breakthrough-callout fade-in">
                    <div class="breakthrough-icon">ğŸ”¬</div>
                    <div class="breakthrough-content">
                        [span_110](start_span)<h4>The Zero-Label Breakthrough</h4>[span_110](end_span)
                        <p>Traditional supervised models need <strong>10,000+ labeled examples</strong> to reach 85% accuracy. Our self-supervised approach achieves comparable performance with <strong>zero labeled examples</strong>â€”learning directly from the inherent structure in satellite data. [span_111](start_span)Result: deploy crop monitoring systems in new regions within days, not months, at <strong>1/50th the cost</strong>.</p>[span_111](end_span)
                    </div>
                </div>
            </div>
        </section>

        <section class="results-section" data-scroll-section>
            <div class="container">
                [span_112](start_span)<span class="section-label">Results</span>[span_112](end_span)
                <h2>Jessore, Bangladesh: 8.27% Crop Stress Discovered</h2>
                <div class="results-summary fade-in">
                    <div class="result-stat">
                        <div class="stat-icon">ğŸŒ¾</div>
                        <div class="stat-content">
                            [span_113](start_span)<div class="stat-number">1,250 kmÂ²</div>[span_113](end_span)
                            <div class="stat-label">Agricultural Region Analyzed</div>
                        </div>
                    </div>
                    <div class="result-stat">
                        <div class="stat-icon">ğŸ”</div>
                        <div class="stat-content">
                            [span_114](start_span)<div class="stat-number">4 Clusters</div>[span_114](end_span)
                            <div class="stat-label">Landscape Patterns Discovered</div>
                        </div>
                    </div>
                    <div class="result-stat">
                        <div class="stat-icon">âš ï¸</div>
                        <div class="stat-content">
                            [span_115](start_span)<div class="stat-number">103.35 kmÂ²</div>[span_115](end_span)
                            <div class="stat-label">Stressed Cropland Identified</div>
                        </div>
                    </div>
                    <div class="result-stat">
                        [span_116](start_span)<div class="stat-icon">â±ï¸</div>[span_116](end_span)
                        <div class="stat-content">
                            <div class="stat-number">6.7 min</div>
                            [span_117](start_span)<div class="stat-label">Total Processing Time</div>[span_117](end_span)
                        </div>
                    </div>
                </div>
                <div class="discovery-details fade-in">
                    [span_118](start_span)<h3>Discovered Cluster Breakdown</h3>[span_118](end_span)
                    <div class="cluster-grid">
                        <div class="cluster-card cluster-1">
                            <div class="cluster-header">
                                [span_119](start_span)<span class="cluster-name">Cluster 1: Healthy Vegetation</span>[span_119](end_span)
                                <span class="cluster-percent">58.3%</span>
                            </div>
                            <div class="cluster-metrics">
                                [span_120](start_span)<span>NDVI: 0.72 (High)</span>[span_120](end_span)
                                <span>NDWI: 0.15 (Low)</span>
                            </div>
                            <p>Dense, photosynthetically active croplandâ€”rice paddies, wheat fields in peak health. [span_121](start_span)High near-infrared reflectance confirms vigorous growth.</p>[span_121](end_span)
                        </div>
                        <div class="cluster-card cluster-2">
                            <div class="cluster-header">
                                [span_122](start_span)<span class="cluster-name">Cluster 2: Water Bodies</span>[span_122](end_span)
                                <span class="cluster-percent">18.5%</span>
                            </div>
                            <div class="cluster-metrics">
                                [span_123](start_span)<span>NDVI: 0.31 (Low)</span>[span_123](end_span)
                                <span>NDWI: 0.68 (Very High)</span>
                            </div>
                            <p>Rivers, canals, irrigation ponds. [span_124](start_span)Near-perfect spectral signature for open waterâ€”low vegetation response, dominant water absorption.</p>[span_124](end_span)
                        </div>
                        <div class="cluster-card cluster-3">
                            <div class="cluster-header">
                                [span_125](start_span)<span class="cluster-name">Cluster 3: Bare Soil</span>[span_125](end_span)
                                <span class="cluster-percent">15.0%</span>
                            </div>
                            <div class="cluster-metrics">
                                [span_126](start_span)<span>NDVI: 0.18 (Very Low)</span>[span_126](end_span)
                                <span>NDWI: 0.08 (Very Low)</span>
                            </div>
                            <p>Fallow fields, recently plowed land, pre-planting bare earth. [span_127](start_span)Minimal vegetation or water signatureâ€”classic soil reflectance spectrum.</p>[span_127](end_span)
                        </div>
                        <div class="cluster-card cluster-4">
                            <div class="cluster-header">
                                [span_128](start_span)<span class="cluster-name">Cluster 4: Stressed Crops</span>[span_128](end_span)
                                <span class="cluster-percent alert">8.27%</span>
                            </div>
                            <div class="cluster-metrics">
                                [span_129](start_span)<span>NDVI: 0.42 (Moderate-Low)</span>[span_129](end_span)
                                <span>NDWI: 0.22 (Moderate)</span>
                            </div>
                            <p><strong>AI-discovered anomaly:</strong> Lower-than-expected NDVI combined with elevated NDWI suggests water stress, nutrient deficiency, or early pest damage. [span_130](start_span)Requires field validation and intervention.</p>[span_130](end_span)
                        </div>
                    </div>
                </div>
            </div>
        </section>

        [span_131](start_span)<section class="visualizations-section" data-scroll-section>[span_131](end_span)
            <div class="container">
                <span class="section-label">Discovered Patterns</span>
                <h2>What the AI Found (Zero Human Labels)</h2>
                <div class="charts-grid fade-in">
                    <div class="chart-card">
                        [span_132](start_span)<h3>Automated Cluster Discovery</h3>[span_132](end_span)
                        <div class="chart-container">
                            <canvas id="chart-cluster-distribution"></canvas>
                        </div>
                    </div>
                    <div class="chart-card">
                        [span_133](start_span)<h3>Cluster Separation (NDVI vs NDWI)</h3>[span_133](end_span)
                        <div class="chart-container">
                            [span_134](start_span)<canvas id="chart-cluster-separation"></canvas>[span_134](end_span)
                        </div>
                    </div>
                    <div class="chart-card">
                        [span_135](start_span)<h3>Sentinel-2 Band Usage</h3>[span_135](end_span)
                        <div class="chart-container">
                            <canvas id="chart-spectral-bands"></canvas>
                        </div>
                    </div>
                    <div class="chart-card">
                        [span_136](start_span)<h3>Automated Processing Timeline</h3>[span_136](end_span)
                        <div class="chart-container">
                            [span_137](start_span)<canvas id="chart-processing-pipeline"></canvas>[span_137](end_span)
                        </div>
                    </div>
                    <div class="chart-card span-2">
                        <h3>AI-Discovered Crop Stress</h3>
                        <div class="chart-container">
                            [span_138](start_span)<canvas id="chart-stress-area"></canvas>[span_138](end_span)
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="impact-section" data-scroll-section>
            <div class="container">
                <span class="section-label">Impact</span>
                <h2>Democratizing Agricultural Intelligence</h2>
                [span_139](start_span)<div class="impact-grid fade-in">[span_139](end_span)
                    <div class="impact-card">
                        <div class="impact-icon">ğŸ’°</div>
                        <h3>Cost Revolution</h3>
                        <div class="impact-stat">
                            [span_140](start_span)<span class="impact-number">$50K</span>[span_140](end_span)
                            <span class="impact-arrow">â†’</span>
                            [span_141](start_span)<span class="impact-number">$0</span>[span_141](end_span)
                        </div>
                        <p>Traditional supervised learning requires <strong>$50,000+ per region</strong> for expert annotation. Self-supervised learning requires <strong>zero</strong>. [span_142](start_span)Deploy crop monitoring anywhere, instantly, at 1/50th the cost.</p>[span_142](end_span)
                    </div>
                    <div class="impact-card">
                        <div class="impact-icon">âš¡</div>
                        [span_143](start_span)<h3>Speed Revolution</h3>[span_143](end_span)
                        <div class="impact-stat">
                            <span class="impact-number">3 months</span>
                            <span class="impact-arrow">â†’</span>
                            [span_144](start_span)<span class="impact-number">7 minutes</span>[span_144](end_span)
                        </div>
                        <p>Manual labeling takes <strong>3 months</strong> of expert labor. Our pipeline processes 1,250 kmÂ² in <strong>under 7 minutes</strong>â€”from raw satellite data to actionable crop stress maps. [span_145](start_span)Real-time agriculture is here.</p>[span_145](end_span)
                    </div>
                    <div class="impact-card">
                        <div class="impact-icon">ğŸŒ</div>
                        <h3>Global Scale</h3>
                        <div class="impact-stat">
                            [span_146](start_span)<span class="impact-number">1 region</span>[span_146](end_span)
                            <span class="impact-arrow">â†’</span>
                            [span_147](start_span)<span class="impact-number">10M+ regions</span>[span_147](end_span)
                        </div>
                        <p>Self-supervised learning removes the bottleneck. Deploy to <strong>any agricultural region worldwide</strong> without retraining, without new labels. [span_148](start_span)From Bangladesh to Brazil to Burkina Fasoâ€”universal crop intelligence.</p>[span_148](end_span)
                    </div>
                </div>
            </div>
        </section>

        <section class="production-section" data-scroll-section>
            <div class="container">
                [span_149](start_span)<div class="production-content fade-in">[span_149](end_span)
                    <span class="section-label">Beyond the Demo</span>
                    <h2>From Proof-of-Concept to Planetary Agriculture</h2>
                    <div class="production-comparison">
                        <div class="comparison-column demo-column">
                            [span_150](start_span)<h4>Demo Version</h4>[span_150](end_span)
                            <ul class="spec-list">
                                <li>1 Sentinel-2 scene</li>
                                [span_151](start_span)<li>4 clusters (K-Means)</li>[span_151](end_span)
                                <li>SimSiam feature learning</li>
                                <li>1,250 kmÂ² coverage</li>
                                [span_152](start_span)<li>Single-region deployment</li>[span_152](end_span)
                            </ul>
                        </div>
                        <div class="comparison-divider">
                            [span_153](start_span)<div class="divider-icon">âš¡</div>[span_153](end_span)
                        </div>
                        <div class="comparison-column production-column">
                            [span_154](start_span)<h4>Production HAWKEYE</h4>[span_154](end_span)
                            <ul class="spec-list">
                                <li><strong>Multi-temporal stacks</strong> (12+ scenes)</li>
                                [span_155](start_span)<li><strong>Hierarchical clustering</strong> (100+ crop types)</li>[span_155](end_span)
                                <li><strong>Foundation models</strong> (pre-trained on 10M+ fields)</li>
                                <li><strong>Continental scale</strong> (1M+ kmÂ²/hour)</li>
                                [span_156](start_span)<li><strong>Global deployment</strong> (200+ countries ready)</li>[span_156](end_span)
                            </ul>
                        </div>
                    </div>
                    [span_157](start_span)<div class="production-features fade-in">[span_157](end_span)
                        <h4>Production System Capabilities:</h4>
                        <div class="feature-tags">
                            <span class="feature-tag">Multi-Crop Recognition</span>
                            [span_158](start_span)<span class="feature-tag">Pest/Disease Detection</span>[span_158](end_span)
                            <span class="feature-tag">Yield Forecasting</span>
                            <span class="feature-tag">Soil Health Mapping</span>
                            [span_159](start_span)<span class="feature-tag">Weekly Updates</span>[span_159](end_span)
                            <span class="feature-tag">Field-Level Precision</span>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <footer class="footer dark-footer" data-scroll-section>
            <div class="footer-content">
                <div class="footer-main">
                    <h2 class="footer-title">
                        <div class="title-line-wrapper">
                            [span_160](start_span)<span class="footer-title-line">The</span>[span_160](end_span)
                        </div>
                        <div class="title-line-wrapper">
                            [span_161](start_span)<span class="footer-title-line">Vision</span>[span_161](end_span)
                        </div>
                    </h2>
                    <p class="footer-tagline">
                        [span_162](start_span)Beyond the algorithm, beyond the noiseâ€”lies the verifiable edge.[span_162](end_span)
                        [span_163](start_span)Our commitment: intellectual honesty, rigorous validation.[span_163](end_span)
                    </p>
                </div>
                <div class="footer-grid">
                    <div class="footer-column">
                        <h3 class="footer-heading">Contact</h3>
                        [span_164](start_span)<a href="mailto:contact@samiulkarim.online" class="footer-link">contact@samiulkarim.online</a>[span_164](end_span)
                    </div>
                    <div class="footer-column">
                        <h3 class="footer-heading">Navigate</h3>
                        [span_165](start_span)<a href="../home.html" class="footer-link">Home</a>[span_165](end_span)
                        <a href="../studio.html" class="footer-link">Studio</a>
                    </div>
                    <div class="footer-column">
                        <h3 class="footer-heading">Connect</h3>
                        [span_166](start_span)<a href="https://github.com" target="_blank" rel="noreferrer" class="footer-link">GitHub</a>[span_166](end_span)
                        <a href="https://linkedin.com" target="_blank" rel="noreferrer" class="footer-link">LinkedIn</a>
                        <a href="https://twitter.com" target="_blank" rel="noreferrer" class="footer-link">Twitter</a>
                    </div>
                </div>
            </div>
        </footer>
    </main>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.5/gsap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.5/ScrollTrigger.min.js"></script>
    <script src="https://unpkg.com/@studio-freight/lenis@1.0.42/dist/lenis.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <script src="demo-animations.js"></script> <script src="demo-crop.js"></script>
</body>
</html>
